{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvgGBd9JNQkL"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "#documents = \"I come from China and i love my hometown Guangdong\"\n",
        "documents = (\"One day, a monkey rides his bike near the river. This time he sees a lion under a tree.\"\\\n",
        "\"The lion runs at him. He is afraid and falls into the river. He can’t swim. He shouts. \"\\\n",
        "\"The rabbit hears him. He jumps into the river. The rabbit swims to the monkey, but he can’t help him. Luckily, an elephant comes along.\"\\\n",
        "\" He is very strong. He helps the rabbit and monkey. Three friends are very happy. They go to the elephant’s home.\"\\\n",
        "\" Then, three of them become good friends.\"\n",
        ")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "853IpAD3NeFc",
        "outputId": "c07230fe-cda8-4aaa-f102-654cbc01b380"
      },
      "source": [
        "len(documents)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "463"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "id": "oTephKXiN89b",
        "outputId": "ba050a24-e07a-4f5b-c40a-a93672cd8592"
      },
      "source": [
        "data = np.array(documents.split())\n",
        "news_df = pd.DataFrame({'document':documents}, index=[0])\n",
        "news_df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One day, a monkey rides his bike near the rive...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            document\n",
              "0  One day, a monkey rides his bike near the rive..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMCRKW4uS_PW"
      },
      "source": [
        "news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z#]\", \" \")#去除字母以外的所有标点符号\n",
        "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))#去除短句\n",
        "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())#把所有数据转为小写"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Unj21VOtS_Rs",
        "outputId": "fbce1eca-930a-41ea-f538-b5e470091f59"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords#导入停止词包，删除体制词\n",
        "stop_words = stopwords.words('english')\n",
        "tokenized_doc = news_df['clean_doc'].apply(lambda x: x.split())#标记化，删除停止词"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzfqMSpgS_XB"
      },
      "source": [
        "detokenized_doc = []#解除标记,数据到这不正常\n",
        "#转换为字符串\n",
        "for i in range(len(news_df)):\n",
        " t = ' '.join(tokenized_doc[i])\n",
        " detokenized_doc.append(t)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV5pmeCxTHYi",
        "outputId": "57f8e9c3-3b06-4467-c596-e4f8d804c03d"
      },
      "source": [
        "news_df['clean_doc'] = detokenized_doc#得到新词\n",
        "news_df['clean_doc']\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    monkey rides bike near river this time sees li...\n",
              "Name: clean_doc, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz4nc2suTHbD"
      },
      "source": [
        "#文档转为词项矩阵\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#max_df表示当前要忽略的文本占比\n",
        "vectorizer = TfidfVectorizer(stop_words='english',max_features =1000,max_df = 1,smooth_idf = True)\n",
        "X = vectorizer.fit_transform(news_df['clean_doc'])#模型适应\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdIDmXPlTHdr",
        "outputId": "14fc35f4-4d6b-4abf-dd5f-5b3bfa507ce3"
      },
      "source": [
        "n = X.shape[-1]\n",
        "X.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdjxKxd_ZWct",
        "outputId": "8e5e0309-7c19-4056-af78-0efa45ebfe72"
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD#导入Truncated分解词义矩阵\n",
        "#SVD表现文档和向量主题\n",
        "#n_compents必须小于当前文本的最大范围\n",
        "svd_model = TruncatedSVD(n_components=n-1, algorithm='randomized', n_iter=100, random_state=122)\n",
        "svd_model.fit(X)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_truncated_svd.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
            "  self.explained_variance_ratio_ = exp_var / full_var\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TruncatedSVD(algorithm='randomized', n_components=27, n_iter=100,\n",
              "             random_state=122, tol=0.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy2Q4LP_cUD0",
        "outputId": "062edbae-8a0c-4f45-bce3-804b8d169b62"
      },
      "source": [
        "len(svd_model.components_)#处理后的文档数据长度"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmllZfHc8JUS",
        "outputId": "46eb0790-55ca-4d98-81b1-8e4879874c60"
      },
      "source": [
        "terms = vectorizer.get_feature_names()\n",
        "\n",
        "for i, comp in enumerate(svd_model.components_):\n",
        "  terms_comp = zip(terms, comp)\n",
        "  sorted_terms = sorted(terms_comp, key=lambda x:x[1], reverse=True)[:7]\n",
        "  print(\"result:\")\n",
        "  for t in sorted_terms:\n",
        "    print(t[0],end=\" \")\n",
        "  print()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "result:\n",
            "monkey rabbit river elephant friends lion bike \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}